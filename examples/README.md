## Default training
To train the model, run this command:
```bash
# to train the pendulum example
python pend_lag_cavae_trainer.py 
# to train the fully-actuated cartpole example
python cart_lag_cavae_trainer.py 
# to train the fully-actuated acrobot example
python acro_lag_cavae_trainer.py 
```


## Training with homogeneous control batch generation and annealing

As expained in the paper (Seciton S3.2), all the results in the main paper are trained with homogeneous control batch generation, where each batch is generated by randomly sampling a part of the training dataset so that all the control inputs in a batch are the same. In practice, an annealing scheme on weight <img src="https://render.githubusercontent.com/render/math?math=\lambda"> might improve training in this case. To train the models with homogeneous control batch generation and annealing, please run

```bash
# to train the pendulum example
python pend_lag_cavae_trainer.py --batch_size 256 --reload_dataloaders_every_epoch True --max_epochs 3000 --homo_u --annealing
# to train the fully-actuated cartpole example
python cart_lag_cavae_trainer.py --batch_size 256 --reload_dataloaders_every_epoch True --max_epochs 3000 --homo_u --annealing
# to train the fully-actuated acrobot example
python acro_lag_cavae_trainer.py --batch_size 256 --reload_dataloaders_every_epoch True --max_epochs 3000 --homo_u --annealing
```

The difference between this and the default training for the Lagrangian_cavae model for prediction is not much, as stated in the paper. I only find that in the Acrobot case the model trained by default training cannot be controlled by energy-based controllers, indicating the physics quantities are not well-learned. For the ablation models, those trained by the default training seems to perform worse than those trained by homogeneous control batch generation. 